---
title: "Modelling US Healthcare Utilisation and Expenditure using 2012 Medical Expenditure Panel Survey Data"
subtitle: "SMM634 Individual Assignment 2025-26"
author:
  - "Benjamin Evans"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output:
  bookdown::pdf_document2:
    includes:
      in_header: preamble.tex
    number_sections: true
    toc: true
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: true
  # runtime: shiny
  bookdown::html_document2:
    self_contained: true
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    code_folding: show
    theme: 
      bootswatch: lumen
      base_font:
        google: "Source Sans Pro"
    highlight: tango
    df_print: paged
# fontsize: 10pt
bibliography: references.bib
---

```{=latex}
\newpage
```

```{=html}
<h1>Information</h1>

This R Markdown document was created as part of an individual assignment for SMM634 at Bayes Business School, City St George's, University of London in Term 1 2025-26.

```

```{r asthetic-header, include=FALSE, echo=FALSE}
# ==============================================================================
# SMM047 Probability and Mathematical Statistics (Subject CS1)
# Individual Coursework
# Author: Benjamin Evans
# Professor:    Professor Rosalba Radice
# Institution:  Bayes Business School - City St George's, University of London
# Date:         05/Dec/2025
# Description:  Term 1 individual project for Analytics Methods for Business. 
# Dependencies:
#   - TBC
# ==============================================================================
# 
# References
# file:///Users/eddy/Downloads/Copula%20Additive%20Distributional%20Regression%20Using%20R_25_11_25_12_44_26.pdf
# 
# 
# 
```

```{r setup-knitr, include=FALSE, echo=FALSE}
#----------------------- Initial setup (knitr settings) -----------------------#
dir.create("fig", showWarnings = FALSE)

# Defaults common to all outputs
knitr::opts_chunk$set(
  echo     = TRUE,
  message  = FALSE,
  warning  = FALSE,
  fig.align = "center",
  out.width = "100%",
  fig.path  = "fig/",
  dpi       = 300
)

# Output-specific settings
if (knitr::is_latex_output()) {
  knitr::opts_chunk$set(
    fig.width = 6,
    fig.height = 4,
    dev = "pdf",
    fig.pos = "ht",
    out.extra = ""
  )
} else {
  knitr::opts_chunk$set(
    fig.width = 6,
    fig.height = 4,
    dev = "svglite"  # or "png"
  )
}
```

```{r setup-qol, include=FALSE, echo=FALSE}
#----------------------------- Clean environment ------------------------------#
rm(list = ls()) # Remove all objects
graphics.off() # Close all graphical devices
cat("\014") # Clean console
```

```{r load-dependencies, include=FALSE, echo=FALSE}
#------------------- Load dependencies / external libraries -------------------#
library(tidyverse)
library(glmnet)  
library(MASS)    
library(ROCR)    
library(GJRM)    # Copula

library(ggplot2)
library(dplyr)
library(patchwork)
library(kableExtra)

# for custom functions
library(clipr) # for banner_comment function qol to annotate code
```

```{r setup-html-app, echo=FALSE, results='asis', eval=knitr::is_html_output(), purl=FALSE}
#------------------------------ HTML link to app ------------------------------#
library(htmltools)

div(style = "background-color: #f8f9fa; padding: 20px; border: 1px solid #e9ecef; border-radius: 5px; text-align: center; margin-bottom: 30px;",
  h3("Bonus Interactive Dashboard Available"),
  p("This static report is accompanied by a live R Shiny dashboard allowing one to test different tickers, exclude specific outlier periods, and adjust bootstrap simulation parameters."),
  a(href = "https://3enji.shinyapps.io/SMM047-202526-Group07-Dashboard/", 
    target = "_blank",
    class = "btn btn-primary", 
    style = "background-color: #007bff; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold;",
    "Update this link!!!! Launch Interactive Dashboard")
)
```

```{r custom-functions, include=FALSE, echo=FALSE}
#---------------------------- Custom QOL functions ----------------------------#
#####################################
# function: banner comments (used to to section up code)
# Usage: banner_comment("Element 1: data cleaning") -> then ctrl + v (or cmd+v)
#####################################
banner_comment <- function(text, width = 80, border = "#", fill = "-") {
  txt <- paste0(" ", text, " ")
  inner_width <- width - 2 * nchar(border)
  banner_string <- ""
  
  if (inner_width <= nchar(txt)) {
    banner_string <- paste0(border, txt, border)
  } else {
    pad_total <- inner_width - nchar(txt)
    pad_left <- pad_total %/% 2
    pad_right <- pad_total - pad_left
    
    banner_string <- paste0(
      border,
      strrep(fill, pad_left),
      txt,
      strrep(fill, pad_right),
      border
    )
  }
  
  cat(banner_string, "\n")
  # copy banner to allow direct pasting (requires clipr)
  clipr::write_clip(banner_string)
  # avoid [1] when printing if want to manually copy
  invisible(banner_string)
}
#####################################
# function: format p-values for text 
# Usage (in-line): `r format_p_vals(ad_test_result$p.value)`
# Usage (console): format_p_vals(ad_test_result$p.value)
#####################################
format_p_vals <- function(p) {
  if (length(p) != 1L || is.na(p)) {
    stop("Error! p must be a single non-missing value")
  }
  if (p > 1) {
    stop("Error! Value greater than 1")
  }
  if (p < 0) {
    stop("Error! Value less than 0")
  }

  if (p >= 0.01) {
    paste0("= ", formatC(p, format = "f", digits = 2))
  } else if (p >= 0.001) {
    paste0("= ", formatC(p, format = "f", digits = 3))
  } else {
    "< 0.001"
  }
}
#####################################
# function: format confidence intervals for tables & text 
# Usage (in-line): `r format_interval(el2_ci_normal_95[1], el2_ci_normal_95[2])`
# Usage (console): format_interval(el2_ci_normal_95[1], el2_ci_normal_95[2])
#####################################
format_interval <- function(lower, upper, digits=3) {
  paste0("[", 
       formatC(lower, format = "f", digits = digits), ", ",
       formatC(upper, format = "f", digits = digits), 
       "]")
}
#####################################
# function: format variable names in green in latex (& normal code in html)
# Usage (in-line): TBI format_var_name
# Usage (console): TBI format_var_name
#####################################
format_var_name <- function(x) {
  if (knitr::is_latex_output()) {
    # replace all "_" with "\_" in va name
    paste0("\\greentt{", gsub("_", "\\\\_", x), "}")
  } else {
    # change to paste0("<code style='color:green'>", x, "</code>") for green
    # paste0("`", x, "`")
    paste0("<code style='color:green'>", x, "</code>")
  }
}
```

# Introduction



```{r Load-data, include=FALSE, echo=FALSE}
#---------------------------- Download / Load data ----------------------------#
meps <- meps_raw <- readr::read_delim("meps.txt", delim = "\t")

meps %>%
  summarise(across(where(is.numeric),
                   ~ paste0(min(.x, na.rm = TRUE), " – ", max(.x, na.rm = TRUE))))

meps <- meps_raw %>%
  mutate(
    # --- 1. standard ordinal / nominal factors ---
    general = factor(
      general,
      levels = 1:5,
      labels = c("Exc", "VGood", "Good", "Fair", "Poor")
    ),
    mental = factor(
      mental,
      levels = 1:5,
      labels = c("Exc", "VGood", "Good", "Fair", "Poor")
    ),
    region = factor(
      region,
      levels = 1:4,
      labels = c("Northeast", "Midwest", "South", "West")
    ),
    ethnicity = factor(
      ethnicity,
      levels = 1:4,
      labels = c("White", "Black", "Native American", "Others")
    ),
    # --- 2. binary factors (0/1 mappings) ---
    gender = factor(gender, levels = c(0, 1), labels = c("Female", "Male")),
    hypertension = factor(
      hypertension,
      levels = c(0, 1),
      labels = c("No", "Yes")
    ),
    hyperlipidemia = factor(
      hyperlipidemia,
      levels = c(0, 1),
      labels = c("No", "Yes")
    ),
    # --- 3. education categories to bin years ---
    # add 'education_cat' for categorical analysis.
    education_cat = case_when(
      education < 12 ~ "< High School",
      education == 12 ~ "High School",
      education > 12 ~ "College +",
      TRUE ~ NA_character_
    ),
    education_cat = factor(
      education_cat,
      levels = c("Less than High School", "High School", "College +")
    ),
    education_cat_detailed = case_when(
      education < 12 ~ "Less than High School",
      education >= 12 & education < 13 ~ "High School Graduate", # Catches 12 and 12.5
      education >= 13 & education < 16 ~ "Some College",       # Catches 13 to 15.9
      education >= 16 & education < 17 ~ "College Graduate",    # Catches 16 and 16.5
      education >= 17 ~ "Post-Graduate",
      TRUE ~ NA_character_
    ),
    # Ensure levels are ordered by SES for proper reference group in regression
    education_cat_detailed = factor(
      education_cat_detailed,
      levels = c(
        "Less than High School", 
        "High School Graduate", 
        "Some College", 
        "College Graduate", 
        "Post-Graduate"
      )
    ),
    # --- 4. Outcomes ---
    has_expense = ifelse(dvexpend > 0, 1, 0)
  )

meps_all <- meps
# exclude individuals with missing information
meps_clean <- na.omit(meps_all)

# "exclude individuals with zero consultations and zero associated expenditures"
# Note: Filtering dvexpend > 0 effectively handles this and prepares for Gamma GLM
meps_pos <- meps_clean %>% filter(dvexpend > 0)

zero_visit_zero_cost <- sum(meps_clean$dvisit == 0 & meps_clean$dvexpend == 0)
pos_visit_zero_cost  <- sum(meps_clean$dvisit > 0 & meps_clean$dvexpend == 0) # Free visits?
zero_visit_pos_cost  <- sum(meps_clean$dvisit == 0 & meps_clean$dvexpend > 0) # Pre-payment?
print(paste("Patients with 0 visits AND 0 cost:", zero_visit_zero_cost))
print(paste("Patients with >0 visits but 0 cost:", pos_visit_zero_cost))
print(paste("Patients with 0 visits but >0 cost:", zero_visit_pos_cost))

# Verify the changes
glimpse(meps)
summary(meps)

mean_visit <- mean(meps_clean$dvisit)
var_visit  <- var(meps_clean$dvisit)

n_total_raw <- nrow(meps_raw)
n_full      <- nrow(meps_clean)
n_pos       <- nrow(meps_pos) 
n_dropped   <- n_total_raw - n_full
n_zeros     <- n_full - n_pos

# Calculate Zero-Cost stats based on the clean dataset
n_zero_cost <- sum(meps_clean$dvexpend == 0)
pct_zero    <- (n_zero_cost / n_full) * 100

# Optional: Stats for visits specifically
n_zero_visit <- sum(meps_clean$dvisit == 0)

# Verify the changes
glimpse(meps_clean)
summary(meps_clean)
```

```{r intro-table, echo = FALSE}
get_cat_compare <- function(df_full, df_pos, var_name, display_name) {
  # Calculate proportions
  get_props <- function(d, v) {
    t <- table(d[[v]])
    formatC(as.numeric(prop.table(t)), format = "f", digits = 2)
  }
  # get labels and values
  clean_labels <- gsub("^[0-9]:\\s*", "", names(table(df_full[[var_name]])))
  # Tibble with one row per category level
  tibble(
    Variable = format_var_name(display_name),
    Description = clean_labels,
    `Full Sample` = get_props(df_full, var_name),
    `Positive Only` = get_props(df_pos, var_name)
  )
}
```


```{r process, echo=FALSE}
# var_summary <- tibble(
#   Variable = names(meps_raw),
#   Type = c("Ordinal Factor", "Ordinal Factor", "Continuous", "Continuous", "Continuous", 
#            "Binary Factor", "Nominal Factor", "Categorical", "Nominal Factor", 
#            "Binary Factor", "Binary Factor", "Count", "Count", "Continuous", "Continuous"),
#   `Raw Range/Levels` = c("1-5", "1-5", "9.4-68.2", "0-Max", "18-65", "0/1", "1-4", "0-17", "1-4", "0/1", "0/1", "0-29", "0-29", "0-Max", "0-Max"),
#   `Analysis Treatment` = c("Factor (Ref: Exc)", "Factor (Ref: Exc)", "Linear/Spline", "Linear (Log?)", "Linear", 
#                            "Factor (Ref: Female)", "Factor (Ref: White)", "Factor (17 levels)", "Factor (Ref: NE)", 
#                            "Factor (Ref: No)", "Factor (Ref: No)", "Response (Count)", "Response (Count)", "Response (Gamma)", "Response")
# )
# 
# # Display Table
# kbl(
#   var_summary, 
#   caption = "MEPS Variable Definitions and Analysis Treatment",
#   booktabs = TRUE
#   ) %>%
#   kable_styling(
#     bootstrap_options = c("striped", "hover")
# )
```


## Background

Quoted from 'The data used in this study are available from the `GJRM.data` package in R.'
@marramodelling2025

MEPS source @ahrq_meps_2024 (foot note that meps.com was down...)

<!-- # ```{r, code = readLines("MarraRadice2025-SuppCode.R")} -->
<!-- # ``` -->


We load the data given via Moodle text file: `meps.txt`...

Data were analysed and the years of education were combined

Healthcare data presents a unique frequency-severity challenge. The dataset
provided includes `r format_var_name("dvisit")` (a count of physician
encounters) and `r format_var_name("dvexpend")` (the total expenditure
associated with those visits). These two variables are intrinsically linked:
total expenditure is the accumulation of costs generated by each discrete visit.

Standard econometric approaches often treat these as independent processes or
model them sequentially. However, unobserved heterogeneity—such as a patient's
latent health frailty or risk aversion—likely influences both the decision to
seek care (frequency) and the intensity of treatment received (severity/cost).
Ignoring this endogeneity can lead to biased estimates. The strategy outlined
here validates GLMs as a baseline while positioning the Copula Additive Model as
the superior, theoretically grounded alternative.

The original dataset contained `r format(n_total_raw, big.mark=",")`
observations. Following standard cleaning procedures, we excluded 
`r n_dropped` individuals due to missing information on covariates. This resulted in a full
analytical sample of `r format(n_full, big.mark=",")` patients.

Furthermore, consistent with the methodology for modelling expenditure amounts
(which requires strictly positive values), we identified a subset of 
`r format(n_pos, big.mark=",")` patients who had at least one physician visit and
associated expenditure. The remaining `r format(n_zeros, big.mark=",")`
individuals (representing `r round((n_zeros/n_full)*100, 1)`% of the clean sample)
had zero utilisation.

Tables 1 and 2 present a comparison of the demographic and health
characteristics between the full sample and the positive-utilisation subset.


```{r initialOverviewCat, echo=FALSE}
tab_cat_comp <- bind_rows(
  get_cat_compare(meps_clean, meps_pos, "gender", "gender"),
  get_cat_compare(meps_clean, meps_pos, "ethnicity", "ethnicity"),
  get_cat_compare(meps_clean, meps_pos, "education_cat", "education_cat"),
  get_cat_compare(meps_clean, meps_pos, "region", "region"),
  get_cat_compare(meps_clean, meps_pos, "hypertension", "hypertension"),
  get_cat_compare(meps_clean, meps_pos, "hyperlipidemia", "hyperlipidemia")
)

header_full <- paste0("Full Sample (N=", format(n_full, big.mark = ","), ")")
header_pos <- paste0(
  "Positive Utilisation (N=",
  format(n_pos, big.mark = ","),
  ")"
)

# Render Categorical Table
# Note: We need to calculate linesep again because we have groups
cat_linesep <- rep("", nrow(tab_cat_comp))
group_ends <- cumsum(rle(as.character(tab_cat_comp$Variable))$lengths)
cat_linesep[group_ends] <- "\\addlinespace"
cat_linesep[nrow(tab_cat_comp)] <- ""

tab_cat_comp %>%
  kbl(
    caption = "Comparison of categorical variables between the full sample and patients with positive utilisation.",
    col.names = c("Variable", "Category", header_full, header_pos),
    booktabs = TRUE,
    escape = FALSE,
    align = c("l", "l", "c", "c"),
    linesep = cat_linesep
  ) %>%
  kable_styling(latex_options = c("hold_position", "repeat_header")) %>%
  collapse_rows(columns = 1, valign = "middle", latex_hline = "major")
```

```{r initialOverviewNum, echo=FALSE}
get_num_compare <- function(
  df_full, 
  df_pos, 
  var_name, 
  display_name, 
  digits = 2, 
  big_mark = "",
  show_mean_se = FALSE
) {
  
  # Helper: Formatting numbers
  fmt <- function(n) {
    formatC(n, format = "f", digits = digits, big.mark = big_mark)
  }
  
  # Helper: Calculate Stat based on Toggle
  calc_stat <- function(d, v) {
    x <- d[[v]]
    
    if (show_mean_se) {
      # --- Calculate Mean (SE) ---
      m <- mean(x, na.rm = TRUE)
      s <- sd(x, na.rm = TRUE)
      n_obs <- sum(!is.na(x))
      se <- s / sqrt(n_obs)
      
      return(paste0(fmt(m), " (", fmt(s), ")"))
      
    } else {
      # --- Calculate Median [IQR] ---
      med <- median(x, na.rm = TRUE)
      q1 <- quantile(x, 0.25, na.rm = TRUE)
      q3 <- quantile(x, 0.75, na.rm = TRUE)
      
      return(paste0(fmt(med), " [", fmt(q1), " – ", fmt(q3), "]"))
    }
  }
  
  # Calculate for both groups
  val_full <- calc_stat(df_full, var_name)
  val_pos  <- calc_stat(df_pos, var_name)
  
  # Build Tibble
  # We use generic column names so bind_rows works even if you mix metrics
  tibble(
    Variable = format_var_name(var_name),
    Description = display_name,
    `Full Sample` = val_full,
    `Positive Only` = val_pos
  )
}

tab_num_comp <- bind_rows(
  # Normal-ish variables -> Use Mean (SE)
  get_num_compare(meps_clean, meps_pos, "bmi", "Body mass index", digits=2, show_mean_se = TRUE),
  get_num_compare(meps_clean, meps_pos, "age", "Age (years)", digits=2, show_mean_se = TRUE),
  get_num_compare(meps_clean, meps_pos, "education", "Education (no. of years)", digits=2, show_mean_se = TRUE),
  
  # Skewed variables -> Keep Median [IQR] (Default)
  get_num_compare(meps_clean, meps_pos, "income", "Income (USD)", digits=0, big_mark=",", show_mean_se = TRUE),
  
  # Utilisation (counts)
  get_num_compare(meps_clean, meps_pos, "dvisit", "Doctor visits", digits=2, show_mean_se = TRUE),
  get_num_compare(meps_clean, meps_pos, "ndvisit", "Non-doctor visits", digits=2, show_mean_se = TRUE),
  
  # Expenditure (costs)
  get_num_compare(meps_clean, meps_pos, "dvexpend", "Doctor expenditure", digits=2, big_mark=",", show_mean_se = TRUE),
  get_num_compare(meps_clean, meps_pos, "ndvexpend", "Non-doctor expenditure", digits=2, big_mark=",", show_mean_se = TRUE)
)
# Render Numerical Table
tab_num_comp %>%
  kbl(
    caption = "Comparison of quantitative variables (Mean & SD).",
    col.names = c("Variable", "Description", header_full, header_pos),
    booktabs = TRUE,
    escape = FALSE,
    align = c("l", "l", "r", "r")
  ) %>%
  kable_styling(latex_options = "hold_position") %>%
  column_spec(1, width = "3cm") %>%
  row_spec(0, bold = TRUE)
```

# Model selection

## Health-care expenditure

Model Selection for Healthcare Expenditure: Given the semi-continuous nature of the expenditure data, we employed a Two-Part model. For the second part (modeling the amount of expenditure for those with positive costs), we utilized Lasso regression (L1 regularization) to select the most predictive features.

The Lasso model was trained on the log-transformed positive expenditure data. Using the 1-Standard-Error rule (λ1se​) to favor parsimony, the algorithm selected Age, Gender, Hypertension, General Health, Mental Health, Ethnicity, Region, and Education as active predictors. Notably, BMI and interaction terms were shrunk to zero, suggesting their variance was adequately captured by the other health indicators (e.g., Hypertension) or they did not provide significant predictive power beyond the main effects.

Consequently, the final Gamma GLM was fitted using only these selected variables.

<!-- Gamma GLM with Log Link: This is the standard "core curriculum" approach for -->
<!-- positive, skewed cost data (as seen in w08_glm.pdf). -->
<!-- Lasso (Shrinkage): Use this for variable selection if you have many predictors -->
<!-- (as per w05_ShrinkageMethods.pdf). -->

<!-- Differentiation: Explicitly state you are assuming independence from utilization -->
<!-- for the sake of the initial model, which the paper does not. -->

```{r modelselection2}
# --- 1. Filter for Positive Expenditure Only ---
# We cannot take the log of 0, and we want to model the *amount* for those who pay.
meps_pos <- subset(meps, dvexpend > 0)

# --- 2. Create Matrix from Positive Data ---
# Ensure we drop NAs so X and y match length
meps_pos <- na.omit(meps_pos)

X_pos <- model.matrix(
  dvexpend ~ age * gender + 
    bmi * hypertension + 
    general + 
    mental + 
    ethnicity + 
    region + 
    education_cat, 
  data = meps_pos
)[, -1]

# --- 3. Define Y as LOG(Expenditure) ---
# This normalizes the skewed cost data
y_pos <- log(meps_pos$dvexpend)

# --- 4. Fit Lasso ---
set.seed(123) # For reproducibility
cv_lasso_exp <- cv.glmnet(X_pos, y_pos, alpha = 1)

# Plot to see the dip (minimum error)
plot(cv_lasso_exp)

# --- 5. Check Active Predictors ---
# Try lambda.1se first (conservative). If still empty, try lambda.min.
coef(cv_lasso_exp, s = "lambda.1se")

m_gamma_final <- glm(
  dvexpend ~ age + gender + hypertension + general + mental + 
             ethnicity + region + education_cat,
  family = Gamma(link = "log"),
  data = meps_pos  # Remember: strictly positive data only!
)

summary(m_gamma_final)

# Optional: Check the fit
par(mfrow=c(2,2))
plot(m_gamma_final)
par(mfrow=c(1,1))

```

```{r model selection}
meps_clean <- na.omit(meps)

# Create Model Matrix (handles dummy creation automatically)
# We exclude the intercept column [-1] because glmnet adds its own
X <- model.matrix(
  dvexpend ~ (age * gender) +
    (bmi * hypertension) +
    general +
    mental +
    ethnicity +
    region +
    education_cat,
  data = meps_clean
)[, -1]

y <- meps_clean$dvexpend

# Fit Lasso with Cross-Validation
cv_lasso <- cv.glmnet(X, y, alpha = 1) 
plot(cv_lasso)

# Extract Active Predictors
coef(cv_lasso, s = "lambda.1se")

# Model A: Poisson GLM
m_pois <- glm(dvisit ~ age + gender + general + ethnicity + region + hypertension, 
              family = poisson(link = "log"), data = meps)

# Model B: Negative Binomial (Addressing Overdispersion)
m_nb <- glm.nb(dvisit ~ age + gender + general + ethnicity + region + hypertension, 
               data = meps)

# Comparison
AIC(m_pois, m_nb) # Lower AIC wins (likely m_nb)
```

```{r model-expendature}
m_probit <- glm(has_expense ~ age + gender + general, 
                family = binomial(link = "probit"), data = meps)

m_gamma <- glm(dvexpend ~ age + gender + general + ethnicity, 
               family = Gamma(link = "log"), 
               data = subset(meps, dvexpend > 0))
```

The dataset consists of `r format(n_total_raw, big.mark=",")` total observations.

An initial inspection of the expenditure data reveals a significant mass of zero values. Specifically, `r format(n_zero_cost, big.mark=",")` patients (`r round(pct_zero, 1)`% of the sample) generated no healthcare expenditure during the survey period.

To model the amount of expenditure, a filtered dataset of the remaining `r format(n_pos, big.mark=",")` patients who incurred positive costs was used.

```{r joint-model}
# eq_visits <- dvisit ~ age + gender + general + mental + ethnicity + region + hypertension
# 
# # Equation 2: Expenditure (Continuous > 0)
# eq_expend <- dvexpend ~ age + gender + general + mental + ethnicity
# 
# # Define the list of equations
# eq_list <- list(eq_visits, eq_expend)
# 
# # Fit the Joint Model
# # margins: "NBI" for count, "GA" for cost
# # Model "B" stands for Bivariate
# joint_model <- gjrm(formula = eq_list, 
#                     data = meps,
#                     margins = c("NBI", "GA"), 
#                     model = "B", 
#                     copula = "N") # Try "J0" for tail dependence
# 
# # Summary
# summary(joint_model)
```

```{=latex}
\newpage
\section*{Appendices}
\addcontentsline{toc}{section}{Appendices}
```

## Health-care utilisation

# Results

## Summary 

## Interpretation

# Discussion 

## Analysis & evaluation

Limitations, analysis and evaluations 

Mention connections between the two here - it's heavily embedded

## Expansion 

# (APPENDIX) Appendices {-} 

<!-- Placeholder code from CS1 project -->
<!-- # Bonus exploration: R Shiny dashboard {#apd-dashboard} -->

<!-- Because there is no corner of our souls we would not turn over for extra credit, -->
<!-- we conducted an additional exploration of an area for future study identified in -->
<!-- the conclusion.  Rather than re-running the analyses for multiple indices, we -->
<!-- developed a dashboard that allows the same workflow to be applied quickly to -->
<!-- other stock market indices. -->

<!-- As R Markdown was used to write up this project, one natural approach would have -->
<!-- been simply to update the ticker symbol and render a new R Markdown document for -->
<!-- each index. While this would work in principle, it is not fully satisfactory: -->
<!-- the document takes time to render (particularly with 50,000-repetition bootstrap -->
<!-- simulations) and each iteration would require manual narrative adjustments. To -->
<!-- address this, we developed an interactive R Shiny dashboard, hosted on -->
<!-- https://www.shinyapps.io/, which provides a dynamic interface for rapid -->
<!-- comparative analysis. The dashboard is available via: -->

<!-- - https://3enji.shinyapps.io/SMM047-202526-Group07-Dashboard/ -->

<!-- Figure \@ref(fig:appendixdashboard1) shows the dashboard start page. Clicking -->
<!-- Run Analysis loads information for the entered Yahoo Finance ticker (with the -->
<!-- default set to `^IXIC`). -->

<!-- Figure \@ref(fig:appendixdashboard2) presents an annotated view of the user -->
<!-- interface.  The dashboard includes (1) a Ticker Selection field that accepts -->
<!-- standard Yahoo Finance symbols; (2–4) Data Cleaning controls, where users can -->
<!-- define the study range and mask a specific outlier period (2020-02-24 to 2020-03-23 in the case of our report); (5) Bootstrap Settings, -->
<!-- allowing users to choose the number of repetitions (to balance accuracy and  -->
<!-- computation time); and (6) Analysis Tabs, which display the cleaned data, -->
<!-- normality tests, and independence diagnostics. -->

<!-- Future development may include support for multiple exclusion windows and -->
<!-- optimisation of the bootstrapping algorithm, which is currently -->
<!-- resource-intensive for large numbers of repetitions. While the present -->
<!-- implementation mirrors the project’s core analysis, there is also scope to -->
<!-- extend this to incorporate additional methods, such as assessing normality using -->
<!-- bootstrapped kurtosis estimates and adding functionality to vary the m value in -->
<!-- the m-out-of-n bootstrap (currently hard coded as m=13). In addition to the -->
<!-- adjusted closing price used in this project, future enhancements could also -->
<!-- allow users to select alternative price series (for example, open, close, or -->
<!-- intraday mid prices) and different aggregation frequencies (for example, daily -->
<!-- or weekly) within the app. -->


```{=latex}
\clearpage
\newpage
```

# Reproducibility, accessibility & declarations (Gen-AI & word count)
<!-- BE note: taken out as we are submitting R file separately -->
<!-- Use: `knitr::purl("cs1-group07.rmd", documentation = 0)` to generate r file -->
<!-- Use: `tools::showNonASCIIfile("cs1-group07.rmd")` to debug -->
<!-- ## R Code Documentation -->

## Reproducibility & accessibility 

An accessible HTML version of this report is available via a public GitHub page:

- !TBI

This report was created in R Markdown. The source code is open source and is
available via:

- !TBI

Changes made to this document were tracked using Git and are also available via
the same repository
(!TBI). 

A bonus interactive dashboard is available via:

- TBI

The source code for this dashboard is available via the project repository: 

- TBI

# R Code

```{=latex}
\small
```
```{r r-code-appendix, ref.label = grep("^setup-", knitr::all_labels(), value = TRUE, invert = TRUE), echo = TRUE, eval = FALSE}
```
```{=latex}
\normalsize
```

---
